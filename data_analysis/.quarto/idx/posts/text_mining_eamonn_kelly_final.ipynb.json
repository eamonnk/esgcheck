{"title":"TU257 - Assignment B","markdown":{"yaml":{"title":"TU257 - Assignment B"},"headingText":"Student: Eamonn Kelly - student #: D24127620","containsRefs":false,"markdown":"\n\n\n\n\n\n#### Part 1 File - Text Mining\n\n\n\n#### Problem Definition:\nEver increasingly people buy products and services off companies with whom they have no day to day dealings or relationship, and with supply chains being so diverse its ever harder to know if the company you are buying from has values which match your own.\n\nThis project is a Proof of Concept (PoC) to try answer the following question: \n\n<u>Question</u>: Can we perform Data Analysis and Classification on company reports to determine and predict how ethical a company is in relation to environmetal, social and governance (esg) criteria?\n\nIn other words, Can we gain a trustworthy ethical insight, into companies esg values based off data they themselves provide in their reports?\n\n### File Structure:\n1. Step1 - Data Identification\n    - 1.1 Reports\n    - 1.2 Identifying which companies to use\n    - 1.3 Obtaining pdf files\n1. Step 2 - Import packages\n1. Step 3 - Data Exploration and Processing\n    - 3.1 define variables\n    - 3.2 try_extract_text function (try-except block to handle errors during pdf extraction)\n    - 3.3 load_proc_file_csv function (to track files which have already been processed)\n    - 3.4 save_proc_files_csv function (to track files which have already been processed)\n    - 3.5 clean_pdf function: cleaning and tokenising pdf data\n    - 3.6 process_file function (handle processing and csv file list and call clean_pdf per pdf file)\n    - 3.7 Create per file data set i.e. data set stored a companyname, filename and exacted text on per file basis - used for model classification\n1. Step 4 - Data Exploration and Analysis\n    - 4.1 view data sample\n    - 4.2 Create Profile report and quick check on data cleanliness i.e. duplicates, nulls values, unusual characters etc\n    - 4.3 Remove empty text data row and verify its successful removal and remaining data integrity\n    - 4.4 Export the data set to json for future re-use and backup and verify file created correctly\n    - 4.5 Data aggregation per company function creation\n    - 4.6 aggregate data on a per company basis - used for general analysis\n    - 4.7 Display Data and Plot of word counts per company\n    - 4.8 Plot - top 50 words with highest frequency per company\n    - 4.9 Plot - wordcloud per word frequency per company\n    - 4.10 Plot - positive ethical word count per company\n    - 4.11 Plot - top 20 highest frequency words across all companies\n    - 4.12 Plot - ethical words occurence per company - normalised per 100 words (as we do nto have even distribution of data for each company)\n    -4.13 Data Exploration ansd Analysis - Conclusions\n1. Step 5 - Classification Models\n    - 5.1 - Split dataset into features and target labels\n    - 5.2 - Verify variables are as expoected\n    - 5.3 - Vectorize the text\n    - 5.4 - Apply tf-idf transformation\n    - 5.5 - Split data into train and test data and verify target variable data\n    - 5.6 - Create Models, perform cross validation and plot ROC AUC\n    - 5.7 - Plot Accuracy data\n    - 5.8 - Apply SMOTE to data to oversample the minority class and verify target variable data\n    - 5.9 - Create the Models using SMOTE data set\n    - 5.10 - Evaluate Model Performance\n1. Step 6 - Conclusions andf Lerarnings\n    - 6.1 Challenges\n    - 6.2 Improvements\n1. Appendix  - References\n\n### Step 1 - Data Identification\n\n#### 1.1 Reports\n- Most readily available data from companies being company reports publihsed on their own websites. Hence decided to use that data.\n- Most companies typically have pages on their sites in the form of the below, where reports can be downloaded\n    - \\investors\n    - \\sustainability\n- we did not include any 'investor' labelled reports as it they appear to be skewed in terms of financial terms occurrence as you would expect.\n- Environment, Social and Governance (ESG) criteria are part of required reporting criteria for companies above a certain size. This is relatively recent requirement, but there should be sufficient data available.\n- Issues:\n    - reports are not standard or always in location or format you would expect.\n    - Some companies do not create single report but create different reports for different criteria and have multiple reports per year.\n    - Some companies embed esg details in graphics on website and only way to access is to scrape html. Decided not top scrape html to try standarise the sources from pdf only, to try make a level playing field in terms of types of sources.\n    - Some reports have reports going back several years readily available, some companies do not.\n\n#### 1.2 Identifying which companies to use\n- Used Industry standard ESG ratings providers such as the below to help identify good and bad esg performers, as well as general web searches for good and bad stories and existing knowledge. There is no single source, rather multiple sources coming together to build a picture of a company. \n    - [MCSI - Morgan Stanley](https://www.msci.com/)\n    - [BCorp](https://www.bcorporation.net/en-us/)\n    - [Susdtainanalytics](https://www.sustainalytics.com/)\n    - others aswell\n- ease of access to reports was also a factor\n- Also tried to have an irish element and choose some companies close to home where possible to keep interesting.\n- Also wanted spread of companies with good and bad reputations for spread of data and landed on the following companies.\n    - [Kerry group](https://www.kerry.com/)\n    - [CRH](https://www.crh.com/)\n    - [Kingspan](https://www.kingspangroup.com/)\n    - [SmurfitKappa](https://www.smurfitkappa.com/) \n    - [aramco](https://www.aramco.com/)\n    - [JBS](https://jbsesg.com/)\n    - [exxonmobil](https://corporate.exxonmobil.com/)\n\n\n\n####  1.3 Obtaining pdf Files\n- Tried to automate report downloading using the following\n    - duckduckgo_search > method in package\n        - this works and can specify sites to search but there are rate limits and could only use to limited affect\n    - Bing search - tried but has been deprecated, no new api keys being issued, need to use chatpgt search\n    - Ended up manually downloading pdf files as had more control over data sets and easier to eliminate noise in unrelated reports. Also quicker due to time constraints investigating how to automate.\n    - Robots.txt : checked *robots.txt* per company site to check allowable usage of data downloads from companies listed\n\n- All obtained company reports were kept in a folder called *<company name>* in the same location as the script. i.e.\n\n        - .scipt.ipynb\n        - \\<company_1_name>\n            - report-1.PDF\n            - report-2.pdf\n        - \\<company_2_name>\n            - report-1.PDF\n            - report-2.pdf\n        - etc. \n\n### Step 2. Import packages\n\n### Step 3 - Data Extraction and Processing\n\n\n3.1 Define variables\nvariables which we will use throughout, placing them at the start so easy to find.\n\n3.2 try_extract_text function (try-except block to handle errors during pdf extraction)\n\n3.3 load_proc_file_csv function (to track files which have already been proecessed)\n\n3.4 save_proc_files_csv function (to track files which have already been proecessed)\n\n3.5 clean_pdf function: cleanifgn and tokenising pdf data\n\n3.6 process_file function (handle processing and csv file list and call clean_pdf per pdf file)\n\n3.7 Create per file data set i.e. data set stored a companyname, filename and exacted text on per file basis - used for model classification\n\n### Step 4 - Data Exploration and Analysis\n\n\n4.1 view data sample\n\n4.2 Create Profile report and quick check on data cleanliness i.e. duplicates, nulls values, unusual characters etc\n\n4.3 Remove empty 'text' data for 'jbs' row and verify its successful removal and remaining data integrity\n\n4.4 Export the data set to json for future re-use and backup and verify file created correctly\n\n4.5 Data aggregation per company function creation\n\n4.6 aggregate data on a per company basis - used for general analysis\n\n4.7 Display Data and Plot of word counts per company\n\n4.8 Plot - top 50 words with highest frequency per company\n\n4.9 Plot - wordcloud per word frequency per company\n\n4.10 Plot - positive ethical word count per company\n\n4.11 Plot - top 20 highest frequency words across all companies\n\n4.12 Plot - ethical words occurence per company - normalised per 1000 words (as we do not have even distribution of data for each company)\n\n4.13 Data Exploration and Analysis - Conclusions\n\n- The word that appears the most across all companies = 'sustainability'\n- words such as 'child', 'slave', 'labour' do not appear in the list of top 20 words across all companies, even the higher esg rated companies.\n- Only 'crh' and 'smurfitKappa' mention slavery in their report\n- *smurfitkappa*, *kerrygroup* and *crh* all mention 'labour' which may be an indication their position, or at least awareness, on labour practices. poorer rated esg companies do not mention 'labour'\n- 'social' and 'governance' terms or their derivatives, while present, do not appear in huge frequencies. Perhaps an indication of the prioritization on environmental aspect of esg.\n- 'transparency' also does not appear frequently.\n- The term 'governance' and possibly 'transparency' could appear more in the investor reports as it may have an emphasis there in relation to management, but the other two terms would be expected to appear, perhaps more, in the sustainability reports. \n\n\nThe final plot or ethical words per company normalised per 1000 words shows promise for our proof of concept.\n- three companies who were chosen for their poor esg ratings, namely *exxonmobil*, *jbs* and *aramco*, all appeared bottom of the list of - positive ethical word counts per 100 words.\n- four companies who were chosen for their high esg ratings,= *kerrygroup*, *crh*, *snmufitkappa* and *kingspan* all appear at the top of the graph.\n- It would require more investigation but could be an indication of an potentially usable approach to differentiate between good and bad esg companies. This was the first indication  of possibility of this being a viable approach. \n- we tried different values for the positive ethical words and settled on the existing list. We wanted to avoid business related terms and focus on key esg values as this is proof of concept focus.\n\n\n## Step 5 - Classification Models\n\n5.1 - Split dataset into features and target labels\n\n5.2 - Verify variables are as expoected\n\n5.3 - Vectorize the text\n\n5.4 -  Apply tf-idf transformation\n\n5.5 - Split data into train and test data and verify target variable data\n\n5.6 - Create Models, perform cross validation and plot ROC AUC\n\n5.7 - Plot Accuracy data\n\n5.8 - Apply SMOTE to data to oversample the minority class and verify target variable data\n\n5.9 - Create the Models using SMOTE data set\n\n5.10 - Plot Accuracy data\n\n5.10 - Evaluate Model Performance\n- Some models performed reasonably well/ Was not expecting this given the limited data size. \n- *MLPClassifier* gives 1.0 ROC curve value and an accuracy of .925 in both pre and post SMOTE Data. This rings alarms bells that data is overfitting, or something is not right. This would require more investigation, would discount this model data.\n- Best performing models\n    - *LogisticRegression* - largest ROC AUC value at .95 but has an accuracy of .75 which is 5th best accuracy. Performed well.\n    - *XGBClassifier* - 0.81 ROC AUC value abut has an accuracy of 0.875. Again performed well.\n    - Other also performed reasonably well.\n\n> LogisticRegression had the followinfg confusion matrix.\n\n```py\n[[ 0  7]\n [ 0 23]]\n\n\n=> 7 False negatives - said 'bad' esg but was 'good' esg company\n=> 23 True Positives - said 'good' esg and was 'good' esg company\n=> 4 True Negatives - said 'bad' esg and was 'bad' esg company\n=> 0 False Positive - said 'good' esg and was 'bad' esg company\n\n```\n\n\n\n> XGBClassifier had the following confusion matrix\n\n```py\n[[ 4  3]\n [ 1 22]]\n\n=> 3 False negatives - said 'bad' esg but was 'good' esg company\n=> 22 True Positives - said 'good' esg and was 'good' esg company\n=> 4 True Negatives - said 'bad' esg and was 'bad' esg company\n=> 0 False Positive - said 'good' esg and was 'bad' esg company\n```\n\nFewer False negatives is important as means telling people the company has poor ethical esg values when infact it has good esg values. This could potentially be unfair and lost business to the companies who were incorrectly labelled. This would need further investigation to try minimise the False negative values.\n\nPost-SMOTE applied data did make a difference. *SVC* has an ROC Value of .99, which again rings alarm bells and means this along with *MLPClassifier* would both be discounted as there is an issue with these being 1.0 or close to 1.0.\n\n*XGBClassifier* and *LogisticRegression* remained stable and similar to the use of pre-smote data, whereas *DecisionTree* and *RandomForest* both deteriorated with SMOTE data.\n \nBest model overall would possibly be a combination of **LogicalRegression** and **XGBClassifier**. These  both performed well and were stable in both scenarios.\n\nOverall, a larger data set is still required to validate the data and performance and further investigation and validation is required. \n\n\n### Step 6 - Conclusions and Learnings\n\nCan we predict whether a company has good or bad esg practices based on reviewing their company reports. This is indicated by \n\n- 1 = good 'esg' company\n- 0 = bad 'esg' company\n\n\nSomewhat surprisingly, two elements wold lead us to believe that this shows promise in text mining analysis and classification as a method to indicate 'esg' company performance\n1. **Part 1.  Data Analysis**\n    - The graph Positive Ethical Keyword Count per Company per 1000 words matches our expectations.\n    - Least Ethical with Lowest Counts per 1000 words = *exxonmobil*, *jbs* and *aramco*\n        - These 3 were selected as they have very low esg rating across our esg ratings i.e. bad esg companies\n    - Companies with the Most ethical word counts per 1000 words  = *kerrygroup*, *crh*, *snmufitkappa* and *kingspan*\n        - These 4 were selected due to their high esg ratings i.e. esg good esg companies\n1. **Part 2. Classification**\n    - The cross fold validation and smote correctly correctly predicted 10 and 5 bad companies respectively. This is tghe most positive sign for me and a good indication of potential, especially given our small data set. true negatives woudl be hardest to predict as companies will use positive terms in reports many times, but the model cna still predict bad esg performers despite this.\n \n\n#### 6.1 Challenges\n- Standardizing and cleaning the date. Not all reports are the same or standardized. Lots of variations in data provided and formats. \nVolume of data. Need to get a lot more company report\n-   Time to process the pdfs is approx between 30 secs and 2 mins per pdf. This adds up when dealing with large numbers of pdfs... It takes approx 40 mins to process our small data set pof pdfs\n-  Companies can stack the reports by repeating positive terms. Always a risk, even if our classification models could see through that in a good few instances in our data set\n- Storage - we need to increase our dataset hugely across a traneg of sources to improve accuracy. Storage may become an issue as data storage needs increase....\n    - we used 44 files across 7 companies which took up aprox 500 MB of space\n\n\n#### 6.2 Improvements\n- tie it into Company Registration Office (CRO) data to include ownership details\n- Get more sample data\n- Include social media and news articles for each company to enhance the data and catch potentisal negativity around it\n- Include court documetn data\n- if have different data sources i.e.company reports, social media, news, courts data can weight those accordingly to give more accurate result.\n\nOverall, this has been surprisingly successful. The initial assumption would be that it would be too difficult to discern a companies esg status solely base don their company reports. However, this shows great potential if the data set could be increased and especially if it can eb broadened to include other sources other than self authored reports.\n\n### Appendix - References\n\n- [oralytics](https://oralytics.com/) >>> #GE2020 Analysing Party Manifestos using Python\n- [https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six) >>> community maintained fork of the original PDFMiner\n- [pdfprimer docs](https://pdfminersix.readthedocs.io)\n- [https://www.nltk.org/](https://www.nltk.org/)\n- [https://docs.python.org/3/howto/regex.html](https://docs.python.org/3/howto/regex.html)\n- [https://regex101.com/](https://docs.python.org/3/howto/regex.html)\n- General ESG references outside of those already included are :\n    - [https://www.responsible-investor.com/](https://www.responsible-investor.com/)\n    - [https://www.knowesg.com/](https://www.knowesg.com)\n    - various news sites\n\n[2] [Python – Convert list of dictionaries to JSON](https://www.geeksforgeeks.org/python-convert-list-of-dictionaries-to-json/)\n","srcMarkdownNoYaml":"\n\n\n\n\n#### Student: Eamonn Kelly - student #: D24127620\n\n#### Part 1 File - Text Mining\n\n\n\n#### Problem Definition:\nEver increasingly people buy products and services off companies with whom they have no day to day dealings or relationship, and with supply chains being so diverse its ever harder to know if the company you are buying from has values which match your own.\n\nThis project is a Proof of Concept (PoC) to try answer the following question: \n\n<u>Question</u>: Can we perform Data Analysis and Classification on company reports to determine and predict how ethical a company is in relation to environmetal, social and governance (esg) criteria?\n\nIn other words, Can we gain a trustworthy ethical insight, into companies esg values based off data they themselves provide in their reports?\n\n### File Structure:\n1. Step1 - Data Identification\n    - 1.1 Reports\n    - 1.2 Identifying which companies to use\n    - 1.3 Obtaining pdf files\n1. Step 2 - Import packages\n1. Step 3 - Data Exploration and Processing\n    - 3.1 define variables\n    - 3.2 try_extract_text function (try-except block to handle errors during pdf extraction)\n    - 3.3 load_proc_file_csv function (to track files which have already been processed)\n    - 3.4 save_proc_files_csv function (to track files which have already been processed)\n    - 3.5 clean_pdf function: cleaning and tokenising pdf data\n    - 3.6 process_file function (handle processing and csv file list and call clean_pdf per pdf file)\n    - 3.7 Create per file data set i.e. data set stored a companyname, filename and exacted text on per file basis - used for model classification\n1. Step 4 - Data Exploration and Analysis\n    - 4.1 view data sample\n    - 4.2 Create Profile report and quick check on data cleanliness i.e. duplicates, nulls values, unusual characters etc\n    - 4.3 Remove empty text data row and verify its successful removal and remaining data integrity\n    - 4.4 Export the data set to json for future re-use and backup and verify file created correctly\n    - 4.5 Data aggregation per company function creation\n    - 4.6 aggregate data on a per company basis - used for general analysis\n    - 4.7 Display Data and Plot of word counts per company\n    - 4.8 Plot - top 50 words with highest frequency per company\n    - 4.9 Plot - wordcloud per word frequency per company\n    - 4.10 Plot - positive ethical word count per company\n    - 4.11 Plot - top 20 highest frequency words across all companies\n    - 4.12 Plot - ethical words occurence per company - normalised per 100 words (as we do nto have even distribution of data for each company)\n    -4.13 Data Exploration ansd Analysis - Conclusions\n1. Step 5 - Classification Models\n    - 5.1 - Split dataset into features and target labels\n    - 5.2 - Verify variables are as expoected\n    - 5.3 - Vectorize the text\n    - 5.4 - Apply tf-idf transformation\n    - 5.5 - Split data into train and test data and verify target variable data\n    - 5.6 - Create Models, perform cross validation and plot ROC AUC\n    - 5.7 - Plot Accuracy data\n    - 5.8 - Apply SMOTE to data to oversample the minority class and verify target variable data\n    - 5.9 - Create the Models using SMOTE data set\n    - 5.10 - Evaluate Model Performance\n1. Step 6 - Conclusions andf Lerarnings\n    - 6.1 Challenges\n    - 6.2 Improvements\n1. Appendix  - References\n\n### Step 1 - Data Identification\n\n#### 1.1 Reports\n- Most readily available data from companies being company reports publihsed on their own websites. Hence decided to use that data.\n- Most companies typically have pages on their sites in the form of the below, where reports can be downloaded\n    - \\investors\n    - \\sustainability\n- we did not include any 'investor' labelled reports as it they appear to be skewed in terms of financial terms occurrence as you would expect.\n- Environment, Social and Governance (ESG) criteria are part of required reporting criteria for companies above a certain size. This is relatively recent requirement, but there should be sufficient data available.\n- Issues:\n    - reports are not standard or always in location or format you would expect.\n    - Some companies do not create single report but create different reports for different criteria and have multiple reports per year.\n    - Some companies embed esg details in graphics on website and only way to access is to scrape html. Decided not top scrape html to try standarise the sources from pdf only, to try make a level playing field in terms of types of sources.\n    - Some reports have reports going back several years readily available, some companies do not.\n\n#### 1.2 Identifying which companies to use\n- Used Industry standard ESG ratings providers such as the below to help identify good and bad esg performers, as well as general web searches for good and bad stories and existing knowledge. There is no single source, rather multiple sources coming together to build a picture of a company. \n    - [MCSI - Morgan Stanley](https://www.msci.com/)\n    - [BCorp](https://www.bcorporation.net/en-us/)\n    - [Susdtainanalytics](https://www.sustainalytics.com/)\n    - others aswell\n- ease of access to reports was also a factor\n- Also tried to have an irish element and choose some companies close to home where possible to keep interesting.\n- Also wanted spread of companies with good and bad reputations for spread of data and landed on the following companies.\n    - [Kerry group](https://www.kerry.com/)\n    - [CRH](https://www.crh.com/)\n    - [Kingspan](https://www.kingspangroup.com/)\n    - [SmurfitKappa](https://www.smurfitkappa.com/) \n    - [aramco](https://www.aramco.com/)\n    - [JBS](https://jbsesg.com/)\n    - [exxonmobil](https://corporate.exxonmobil.com/)\n\n\n\n####  1.3 Obtaining pdf Files\n- Tried to automate report downloading using the following\n    - duckduckgo_search > method in package\n        - this works and can specify sites to search but there are rate limits and could only use to limited affect\n    - Bing search - tried but has been deprecated, no new api keys being issued, need to use chatpgt search\n    - Ended up manually downloading pdf files as had more control over data sets and easier to eliminate noise in unrelated reports. Also quicker due to time constraints investigating how to automate.\n    - Robots.txt : checked *robots.txt* per company site to check allowable usage of data downloads from companies listed\n\n- All obtained company reports were kept in a folder called *<company name>* in the same location as the script. i.e.\n\n        - .scipt.ipynb\n        - \\<company_1_name>\n            - report-1.PDF\n            - report-2.pdf\n        - \\<company_2_name>\n            - report-1.PDF\n            - report-2.pdf\n        - etc. \n\n### Step 2. Import packages\n\n### Step 3 - Data Extraction and Processing\n\n\n3.1 Define variables\nvariables which we will use throughout, placing them at the start so easy to find.\n\n3.2 try_extract_text function (try-except block to handle errors during pdf extraction)\n\n3.3 load_proc_file_csv function (to track files which have already been proecessed)\n\n3.4 save_proc_files_csv function (to track files which have already been proecessed)\n\n3.5 clean_pdf function: cleanifgn and tokenising pdf data\n\n3.6 process_file function (handle processing and csv file list and call clean_pdf per pdf file)\n\n3.7 Create per file data set i.e. data set stored a companyname, filename and exacted text on per file basis - used for model classification\n\n### Step 4 - Data Exploration and Analysis\n\n\n4.1 view data sample\n\n4.2 Create Profile report and quick check on data cleanliness i.e. duplicates, nulls values, unusual characters etc\n\n4.3 Remove empty 'text' data for 'jbs' row and verify its successful removal and remaining data integrity\n\n4.4 Export the data set to json for future re-use and backup and verify file created correctly\n\n4.5 Data aggregation per company function creation\n\n4.6 aggregate data on a per company basis - used for general analysis\n\n4.7 Display Data and Plot of word counts per company\n\n4.8 Plot - top 50 words with highest frequency per company\n\n4.9 Plot - wordcloud per word frequency per company\n\n4.10 Plot - positive ethical word count per company\n\n4.11 Plot - top 20 highest frequency words across all companies\n\n4.12 Plot - ethical words occurence per company - normalised per 1000 words (as we do not have even distribution of data for each company)\n\n4.13 Data Exploration and Analysis - Conclusions\n\n- The word that appears the most across all companies = 'sustainability'\n- words such as 'child', 'slave', 'labour' do not appear in the list of top 20 words across all companies, even the higher esg rated companies.\n- Only 'crh' and 'smurfitKappa' mention slavery in their report\n- *smurfitkappa*, *kerrygroup* and *crh* all mention 'labour' which may be an indication their position, or at least awareness, on labour practices. poorer rated esg companies do not mention 'labour'\n- 'social' and 'governance' terms or their derivatives, while present, do not appear in huge frequencies. Perhaps an indication of the prioritization on environmental aspect of esg.\n- 'transparency' also does not appear frequently.\n- The term 'governance' and possibly 'transparency' could appear more in the investor reports as it may have an emphasis there in relation to management, but the other two terms would be expected to appear, perhaps more, in the sustainability reports. \n\n\nThe final plot or ethical words per company normalised per 1000 words shows promise for our proof of concept.\n- three companies who were chosen for their poor esg ratings, namely *exxonmobil*, *jbs* and *aramco*, all appeared bottom of the list of - positive ethical word counts per 100 words.\n- four companies who were chosen for their high esg ratings,= *kerrygroup*, *crh*, *snmufitkappa* and *kingspan* all appear at the top of the graph.\n- It would require more investigation but could be an indication of an potentially usable approach to differentiate between good and bad esg companies. This was the first indication  of possibility of this being a viable approach. \n- we tried different values for the positive ethical words and settled on the existing list. We wanted to avoid business related terms and focus on key esg values as this is proof of concept focus.\n\n\n## Step 5 - Classification Models\n\n5.1 - Split dataset into features and target labels\n\n5.2 - Verify variables are as expoected\n\n5.3 - Vectorize the text\n\n5.4 -  Apply tf-idf transformation\n\n5.5 - Split data into train and test data and verify target variable data\n\n5.6 - Create Models, perform cross validation and plot ROC AUC\n\n5.7 - Plot Accuracy data\n\n5.8 - Apply SMOTE to data to oversample the minority class and verify target variable data\n\n5.9 - Create the Models using SMOTE data set\n\n5.10 - Plot Accuracy data\n\n5.10 - Evaluate Model Performance\n- Some models performed reasonably well/ Was not expecting this given the limited data size. \n- *MLPClassifier* gives 1.0 ROC curve value and an accuracy of .925 in both pre and post SMOTE Data. This rings alarms bells that data is overfitting, or something is not right. This would require more investigation, would discount this model data.\n- Best performing models\n    - *LogisticRegression* - largest ROC AUC value at .95 but has an accuracy of .75 which is 5th best accuracy. Performed well.\n    - *XGBClassifier* - 0.81 ROC AUC value abut has an accuracy of 0.875. Again performed well.\n    - Other also performed reasonably well.\n\n> LogisticRegression had the followinfg confusion matrix.\n\n```py\n[[ 0  7]\n [ 0 23]]\n\n\n=> 7 False negatives - said 'bad' esg but was 'good' esg company\n=> 23 True Positives - said 'good' esg and was 'good' esg company\n=> 4 True Negatives - said 'bad' esg and was 'bad' esg company\n=> 0 False Positive - said 'good' esg and was 'bad' esg company\n\n```\n\n\n\n> XGBClassifier had the following confusion matrix\n\n```py\n[[ 4  3]\n [ 1 22]]\n\n=> 3 False negatives - said 'bad' esg but was 'good' esg company\n=> 22 True Positives - said 'good' esg and was 'good' esg company\n=> 4 True Negatives - said 'bad' esg and was 'bad' esg company\n=> 0 False Positive - said 'good' esg and was 'bad' esg company\n```\n\nFewer False negatives is important as means telling people the company has poor ethical esg values when infact it has good esg values. This could potentially be unfair and lost business to the companies who were incorrectly labelled. This would need further investigation to try minimise the False negative values.\n\nPost-SMOTE applied data did make a difference. *SVC* has an ROC Value of .99, which again rings alarm bells and means this along with *MLPClassifier* would both be discounted as there is an issue with these being 1.0 or close to 1.0.\n\n*XGBClassifier* and *LogisticRegression* remained stable and similar to the use of pre-smote data, whereas *DecisionTree* and *RandomForest* both deteriorated with SMOTE data.\n \nBest model overall would possibly be a combination of **LogicalRegression** and **XGBClassifier**. These  both performed well and were stable in both scenarios.\n\nOverall, a larger data set is still required to validate the data and performance and further investigation and validation is required. \n\n\n### Step 6 - Conclusions and Learnings\n\nCan we predict whether a company has good or bad esg practices based on reviewing their company reports. This is indicated by \n\n- 1 = good 'esg' company\n- 0 = bad 'esg' company\n\n\nSomewhat surprisingly, two elements wold lead us to believe that this shows promise in text mining analysis and classification as a method to indicate 'esg' company performance\n1. **Part 1.  Data Analysis**\n    - The graph Positive Ethical Keyword Count per Company per 1000 words matches our expectations.\n    - Least Ethical with Lowest Counts per 1000 words = *exxonmobil*, *jbs* and *aramco*\n        - These 3 were selected as they have very low esg rating across our esg ratings i.e. bad esg companies\n    - Companies with the Most ethical word counts per 1000 words  = *kerrygroup*, *crh*, *snmufitkappa* and *kingspan*\n        - These 4 were selected due to their high esg ratings i.e. esg good esg companies\n1. **Part 2. Classification**\n    - The cross fold validation and smote correctly correctly predicted 10 and 5 bad companies respectively. This is tghe most positive sign for me and a good indication of potential, especially given our small data set. true negatives woudl be hardest to predict as companies will use positive terms in reports many times, but the model cna still predict bad esg performers despite this.\n \n\n#### 6.1 Challenges\n- Standardizing and cleaning the date. Not all reports are the same or standardized. Lots of variations in data provided and formats. \nVolume of data. Need to get a lot more company report\n-   Time to process the pdfs is approx between 30 secs and 2 mins per pdf. This adds up when dealing with large numbers of pdfs... It takes approx 40 mins to process our small data set pof pdfs\n-  Companies can stack the reports by repeating positive terms. Always a risk, even if our classification models could see through that in a good few instances in our data set\n- Storage - we need to increase our dataset hugely across a traneg of sources to improve accuracy. Storage may become an issue as data storage needs increase....\n    - we used 44 files across 7 companies which took up aprox 500 MB of space\n\n\n#### 6.2 Improvements\n- tie it into Company Registration Office (CRO) data to include ownership details\n- Get more sample data\n- Include social media and news articles for each company to enhance the data and catch potentisal negativity around it\n- Include court documetn data\n- if have different data sources i.e.company reports, social media, news, courts data can weight those accordingly to give more accurate result.\n\nOverall, this has been surprisingly successful. The initial assumption would be that it would be too difficult to discern a companies esg status solely base don their company reports. However, this shows great potential if the data set could be increased and especially if it can eb broadened to include other sources other than self authored reports.\n\n### Appendix - References\n\n- [oralytics](https://oralytics.com/) >>> #GE2020 Analysing Party Manifestos using Python\n- [https://github.com/pdfminer/pdfminer.six](https://github.com/pdfminer/pdfminer.six) >>> community maintained fork of the original PDFMiner\n- [pdfprimer docs](https://pdfminersix.readthedocs.io)\n- [https://www.nltk.org/](https://www.nltk.org/)\n- [https://docs.python.org/3/howto/regex.html](https://docs.python.org/3/howto/regex.html)\n- [https://regex101.com/](https://docs.python.org/3/howto/regex.html)\n- General ESG references outside of those already included are :\n    - [https://www.responsible-investor.com/](https://www.responsible-investor.com/)\n    - [https://www.knowesg.com/](https://www.knowesg.com)\n    - various news sites\n\n[2] [Python – Convert list of dictionaries to JSON](https://www.geeksforgeeks.org/python-convert-list-of-dictionaries-to-json/)\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"output-file":"text_mining_eamonn_kelly_final.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.31","theme":["cosmo","brand"],"title-block-banner":true,"title":"TU257 - Assignment B"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}